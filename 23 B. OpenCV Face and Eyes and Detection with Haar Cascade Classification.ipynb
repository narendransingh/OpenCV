{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Casade Classifier Face and Eyes\n",
    "\n",
    "So object detect using Haar Classifier is effect object detection method. Is ML based approach where Cascade fn. istrained for positive and negative images.\n",
    "\n",
    "Classifier (namely a cascade boosted classifier working with haar feature) is trained with few hundreds sample view of perticular oject(face or a car), called postive samples that are scaled to size 20x20 and negative - arbitriary image sample of size\n",
    "\n",
    "After train it can be applied to region of interest, classifier out are 1 is region to show the object else 0. \n",
    "\n",
    "Also on github we can find already trained xml files, can use that as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define our classifier .\n",
    "\n",
    "Use the CascadeClassifier function. The classifer works on grayscale image, we conver input image to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read image\n",
    "image = cv.imread('faces.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver to grayscale\n",
    "\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the faces inside the image. We use detectMulitscale function from Haar Cascade\n",
    "\n",
    "scale_factor - how much image size to reduce at each image scale\n",
    "minNeighbor - how many neighbor each candidate rectange should have to retain it.\n",
    "output - vector of rectangles, where each rectangle contains the detected object, the rectangle may partially be outside the original image if it is on the corner. \n",
    "#values:(image, scalefactor, minNeighbor)\n",
    "\n",
    "### For Eye detection\n",
    "\n",
    "Region of interest will be face, as eye will be inside face. We already detected the face, this will be the region of interest and we will use the grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable to store output of vectors of rectangles\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4) #output will have rectangle coordinate for each detected image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the x and y with width and height to iterate inside the image\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    \n",
    "    #draw rectangle using the coordiates.\n",
    "    #values:(img, pt1, pt2, color,thickness)\n",
    "    cv.rectangle(image, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    \n",
    "    #Region of Interest will be find in grayscale image. In gray image we use the index of face we found using HAAR\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    \n",
    "    #ROI on color image\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    \n",
    "    #detect eyes using HAAR function\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    \n",
    "    #iterate over all the eyes on face\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        \n",
    "        #draw rectangle over eyes\n",
    "        cv.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0,255,0), 2)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('face', image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To detect face and eyes in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0) #for front camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now if cap is opened\n",
    "\n",
    "while (cap.isOpened()): #gives bool value\n",
    "    \n",
    "    #we read every frame\n",
    "    _,img = cap.read() \n",
    "    \n",
    "    #convert the frame image to gray\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #use cascade funtion to detect face on frame\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    #draw rectange on the face\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "        \n",
    "        #roi in gray image\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        #roi in color image/frame\n",
    "        roi_color = image[y:y+h, x:x+w]\n",
    "        \n",
    "        #detect eyes using HAAR and get the coordinate\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        #iterate over all the eyes on face\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "        \n",
    "            #draw rectangle over eyes\n",
    "            cv.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0,255,0), 5)\n",
    "        \n",
    "    #display the video\n",
    "    cv.imshow('face', img)\n",
    "\n",
    "    if  cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)\n",
    "cv.waitKey(1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
